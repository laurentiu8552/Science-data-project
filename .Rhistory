"Garden table",
"Curtain",
"armchair",
"Mattresses",
"top mattress",
"Sheets",
"Decoration",
"Sheets",
"Sheets",
"Bed Linen",
"Bed Linen",
"Sheets",
"top mattress",
"Sheets",
"Mattresses",
"Bed Linen",
"Bed Linen",
"continental bed",
"Bed Linen",
"Mattresses",
"Mattresses",
"Mattresses",
"Mattresses",
"chest of drawers",
"pedestal",
"Curtain",
"Towel",
"Bed Linen",
"Accessorries",
"Mattresses",
"Accessorries",
"Sheets",
"Bed Linen",
"Accessorries",
"Mattresses",
"shelving unit",
"continental bed",
"Accessorries",
"Mattresses",
"decoration",
"nest of tables",
"Curtain",
"Mattresses",
"Bed Linen",
"bedside table",
"lamp",
"Garden cushion",
"Bed Linen",
"Bed Linen",
"top mattress",
"Mattresses",
"Accessorries",
"Curtain",
"Accessorries",
"continental bed",
"Bed Linen",
"Mattresses",
"office chair",
"sofa bed with chaise longue",
"dining chair",
"dining chair",
"Accessorries",
"Accessorries",
"Accessorries",
"Bed Linen",
"top mattress",
"Accessorries",
"top mattress",
"Mattresses",
"top mattress",
"Towel",
"TableTextile",
"Mattresses",
"Accessorries",
"sofa bed",
"Decoration",
"Accessorries",
"top mattress",
"Mattresses",
"Mattresses",
"Mattresses"
)
# d, combine all three vectors into a data frame named 'lookup'
lookup <- data.frame(
product_title = product_title,
product_group_level_1 = product_group_level_1,
product_category_level_2 = product_category_level_2,
stringsAsFactors = FALSE
)
# e, Print to confirm
print(lookup, n = nrow(lookup))
# f, now the actual imputation part
# create data_joined by joining data with lookup on product_title
data <- data %>%
left_join(lookup, by = "product_title", suffix = c("", ".lkp")) %>%
# replace NAs in original columns with the lookup columns
mutate(
product_group_level_1 = coalesce(product_group_level_1, product_group_level_1.lkp),
product_category_level_2 = coalesce(product_category_level_2, product_category_level_2.lkp  )
) %>%
# remove the extra lookup columns
dplyr::select(-ends_with(".lkp"))
# Convert the 'date' column to Date type
data$date <- as.Date(data$date, format = "%d.%m.%Y")
# Convert all non-numeric columns (besides 'date') to factors
data[] <- lapply(data, function(x) if(is.character(x)) as.factor(x) else x)
# Impute NA customer id's with 999999999 for now. Will be removed in CLV probably
data <- data %>%
mutate(customer_id = replace_na(customer_id, 9999999999))
sum(is.na(data))
skimr::skim(data)
#Visualization of the 3 rfm variables
data_clean_rfm <- data[data$customer_id != 9999999999, ]
# Revenue histogram
hist(data_clean_rfm$revenue, main = "Histogram of Revenue", col = "blue", border = "black")
# Check for NAs
sum(is.na(data_clean_rfm$revenue))      # Count NAs in revenue
# Customer ID bar plot - Delete later, useless, including the NA checks
cust_freq <- table(data_clean_rfm$customer_id)
# Filter to only those with frequency >= 10
cust_freq_filtered <- cust_freq[cust_freq >= 35]
barplot(cust_freq_filtered, main = "Customer ID Distribution", col = "blue", las = 2, ylim = c(0, 80))
# Date bar plot
barplot(table(data_clean_rfm$date), main = "Date Distribution", col = "blue")
sum(is.na(data_clean_rfm$date))         # Count NAs in date
#CAN BE SEEN no NAs and also no negative variables, can proceed with the RFM model running
# 1. Aggregate to Order-Level Data
order_level_data <- data_clean_rfm %>%
dplyr::select(date, order_id, customer_id, revenue) %>%  # keep only relevant columns
dplyr::group_by(order_id, customer_id, date) %>%         # group by order_id, customer_id, and date
dplyr::summarise(total_revenue = sum(revenue, na.rm = TRUE), .groups = "drop")  # sum revenue and ungroup
# 2. Set Analysis Date (using the day after your last order date)
analysis_date <- as.Date("2025-01-01")
# 3. Run the RFM Analysis using the Aggregated Data
# Note: We now use 'total_revenue' instead of 'revenue'
rfm_result <- rfm_table_order(order_level_data,
customer_id,
date,
total_revenue,
analysis_date = analysis_date)
# 4. Visualize RFM Results
rfm_plot_heatmap(rfm_result)
rfm_plot_bar_chart(rfm_result)
# 5. Define RFM Segment Categories and Thresholds
segment_names <- c("Champions", "Loyal Customers", "Potential Loyalist",
"New Customers", "Promising", "Need Attention", "About To Sleep",
"At Risk", "Can't Lose Them", "Lost")
# For Recency
summary(rfm_result$rfm$recency_score)
hist(rfm_result$rfm$recency_score, main = "Recency Distribution", xlab = "Recency")
# For Frequency
summary(rfm_result$rfm$frequency_score)
hist(rfm_result$rfm$frequency_score, main = "Frequency Distribution", xlab = "Frequency")
# For Monetary
summary(rfm_result$rfm$monetary_score)
hist(rfm_result$rfm$monetary_score, main = "Monetary Distribution", xlab = "Monetary")
quantile(rfm_result$rfm$recency_score, probs = seq(0, 1, 0.2))
quantile(rfm_result$rfm$frequency_score, probs = seq(0, 1, 0.2))
quantile(rfm_result$rfm$monetary_score, probs = seq(0, 1, 0.2))
# For each customer, count the number of orders (each row in order_level_data is an order)
customer_orders <- order_level_data %>%
dplyr::group_by(customer_id) %>%
dplyr::summarise(num_orders = dplyr::n(), .groups = "drop")
# Count how many customers fall into each order count bucket
freq_dist <- customer_orders %>%
dplyr::count(num_orders)
print(freq_dist)
recency_lower   <- c(4, 2, 3, 4, 3, 2, 2, 1, 1, 1)
recency_upper   <- c(5, 5, 5, 5, 4, 3, 3, 2, 1, 2)
frequency_lower <- c(5, 5, 3, 1, 1, 1, 1, 1, 1, 1)
frequency_upper <- c(5, 5, 5, 1, 1, 1, 1, 1, 1, 1)
monetary_lower  <- c(4, 3, 1, 1, 1, 2, 1, 2, 4, 1)
monetary_upper  <- c(5, 5, 3, 1, 1, 3, 2, 5, 5, 2)
# 6. Apply Segmentation Based on RFM Scores
segment <- rfm_segment(rfm_result,
segment_names,
recency_lower, recency_upper,
frequency_lower, frequency_upper,
monetary_lower, monetary_upper)
# 7. View the Segmented Customers
head(segment)
# 8. Visualize RFM Segments
rfm_plot_median_recency(segment, sort = TRUE)
rfm_plot_median_monetary(segment, sort = TRUE)
rfm_plot_median_frequency(segment, sort = TRUE)
# Load packages
library(dplyr)
library(tidyr)
library(recommenderlab)
# Step 1: Create binary interaction dataset (purchases)
data_rcs <- data
interactions <- data_rcs %>%
dplyr::select(customer_id, product_title) %>%
distinct() %>%
mutate(purchased = 1)
# Step 2: Sample a subset of customers
set.seed(42)
sample_customers <- sample(unique(interactions$customer_id), 1000)
sample_data <- interactions %>%
filter(customer_id %in% sample_customers)
# Step 3: Filter to top 100 most purchased products
top_products <- sample_data %>%
dplyr::count(product_title, sort = TRUE) %>%
slice_head(n = 100) %>%
pull(product_title)
sample_data <- sample_data %>%
filter(product_title %in% top_products)
# Step 4: Create wide user-product matrix (1 = purchased)
interaction_matrix <- sample_data %>%
tidyr::pivot_wider(
names_from = product_title,
values_from = purchased,
values_fill = list(purchased = 0)
)
# Step 5: Convert to matrix format
customer_ids <- interaction_matrix$customer_id
interaction_matrix <- interaction_matrix %>% dplyr::select(-customer_id)
mat <- as.matrix(interaction_matrix)
rownames(mat) <- customer_ids
# Step 6: Convert to binaryRatingMatrix
binary_ratings <- as(mat, "binaryRatingMatrix")
# Remove sparse customers/products
# Keep customers with more than 2 items and products with more than 5 purchases
filtered_ratings <- binary_ratings[rowCounts(binary_ratings) > 2, colCounts(binary_ratings) > 5]
# Create evaluation scheme for cross-validation
set.seed(42)
evaluation_scheme <- evaluationScheme(
filtered_ratings,
method = "cross-validation",  # Use cross-validation
k = 5,                        # 5-fold cross-validation
given = -1,                   # Use all items for training
goodRating = 1                # Define what's considered a positive rating
)
# Parameter tuning - define grid of parameters to try
param_grid <- expand.grid(
k = c(10, 20, 30, 50, 100),      # Different numbers of neighbors
method = c("cosine", "pearson")  # Different similarity measures
)
# Run evaluation with all parameter combinations
results_list <- list()
for (i in 1:nrow(param_grid)) {
current_params <- list(k = param_grid$k[i], method = as.character(param_grid$method[i]))
# Print current parameters being tested
cat("Testing parameters:", paste(names(current_params), current_params, sep = "=", collapse = ", "), "\n")
# Evaluate with current parameters
results_list[[i]] <- evaluate(
evaluation_scheme,
method = "IBCF",
n = c(1, 3, 5, 10),            # Number of recommendations to make
parameter = current_params     # Current parameter combination
)
}
# Load packages
library(dplyr)
library(tidyr)
library(recommenderlab)
# Step 1: Create binary interaction dataset (purchases)
data_rcs <- data
interactions <- data_rcs %>%
dplyr::select(customer_id, product_title) %>%
distinct() %>%
mutate(purchased = 1)
# Step 2: Sample a subset of customers
set.seed(42)
sample_customers <- sample(unique(interactions$customer_id), 1000)
sample_data <- interactions %>%
filter(customer_id %in% sample_customers)
# Step 3: Filter to top 100 most purchased products
top_products <- sample_data %>%
dplyr::count(product_title, sort = TRUE) %>%
slice_head(n = 100) %>%
pull(product_title)
sample_data <- sample_data %>%
filter(product_title %in% top_products)
# Step 4: Create wide user-product matrix (1 = purchased)
interaction_matrix <- sample_data %>%
tidyr::pivot_wider(
names_from = product_title,
values_from = purchased,
values_fill = list(purchased = 0)
)
# Step 5: Convert to matrix format
customer_ids <- interaction_matrix$customer_id
interaction_matrix <- interaction_matrix %>% dplyr::select(-customer_id)
mat <- as.matrix(interaction_matrix)
rownames(mat) <- customer_ids
# Step 6: Convert to binaryRatingMatrix
binary_ratings <- as(mat, "binaryRatingMatrix")
# Remove sparse customers/products
# Keep customers with more than 2 items and products with more than 5 purchases
filtered_ratings <- binary_ratings[rowCounts(binary_ratings) > 2, colCounts(binary_ratings) > 5]
# MODIFIED APPROACH: Use recommenderlab's built-in cross-validation
# This handles the item distribution properly to avoid dimension mismatches
set.seed(42)
# Define the parameter grid
k_values <- c(10, 20, 30, 50, 100)
similarity_methods <- c("cosine", "pearson")
# Create a list to store results
cv_results <- list()
# Run cross-validation for each parameter combination
for (k_val in k_values) {
for (sim_method in similarity_methods) {
param_name <- paste0("k", k_val, "_", sim_method)
cat("Testing parameters: k =", k_val, ", method =", sim_method, "\n")
# Create evaluation scheme with 5-fold cross-validation
evaluation_scheme <- evaluationScheme(
filtered_ratings,
method = "cross-validation",
k = 5,
given = -1,
goodRating = 1
)
# Evaluate with current parameters
current_result <- evaluate(
evaluation_scheme,
method = "IBCF",
n = c(1, 3, 5, 10),
parameter = list(k = k_val, method = sim_method)
)
# Store results
cv_results[[param_name]] <- current_result
}
}
# Load packages
library(dplyr)
library(tidyr)
library(recommenderlab)
# Step 1: Create binary interaction dataset (purchases)
data_rcs <- data
interactions <- data_rcs %>%
dplyr::select(customer_id, product_title) %>%
distinct() %>%
mutate(purchased = 1)
# Step 2: Sample a subset of customers
set.seed(42)
sample_customers <- sample(unique(interactions$customer_id), 1000)
sample_data <- interactions %>%
filter(customer_id %in% sample_customers)
# Step 3: Filter to top 100 most purchased products
top_products <- sample_data %>%
dplyr::count(product_title, sort = TRUE) %>%
slice_head(n = 100) %>%
pull(product_title)
sample_data <- sample_data %>%
filter(product_title %in% top_products)
# Step 4: Create wide user-product matrix (1 = purchased)
interaction_matrix <- sample_data %>%
tidyr::pivot_wider(
names_from = product_title,
values_from = purchased,
values_fill = list(purchased = 0)
)
# Step 5: Convert to matrix format
customer_ids <- interaction_matrix$customer_id
interaction_matrix <- interaction_matrix %>% dplyr::select(-customer_id)
mat <- as.matrix(interaction_matrix)
rownames(mat) <- customer_ids
# Step 6: Convert to binaryRatingMatrix
binary_ratings <- as(mat, "binaryRatingMatrix")
# Remove sparse customers/products
# Keep customers with more than 2 items and products with more than 5 purchases
filtered_ratings <- binary_ratings[rowCounts(binary_ratings) > 2, colCounts(binary_ratings) > 5]
# SIMPLER APPROACH: Manual k-fold cross-validation
set.seed(42)
# Define parameter combinations to test
k_values <- c(10, 20, 30, 50)
methods <- c("cosine")  # Limiting to one method to simplify
# Create a data frame to store results
results_df <- data.frame()
# Number of folds
n_folds <- 3
# Create fold assignments
user_indices <- 1:nrow(filtered_ratings)
fold_assignments <- sample(rep(1:n_folds, length.out = length(user_indices)))
# For each parameter combination
for (k_val in k_values) {
cat("Testing k =", k_val, "\n")
# For each fold
fold_results <- list()
for (fold in 1:n_folds) {
cat("  Fold", fold, "of", n_folds, "\n")
# Split data
test_indices <- user_indices[fold_assignments == fold]
train_indices <- user_indices[fold_assignments != fold]
train_data <- filtered_ratings[train_indices, ]
test_data <- filtered_ratings[test_indices, ]
# Build model
model <- Recommender(train_data, method = "IBCF", parameter = list(k = k_val))
# Get top 5 recommendations for test users
recom <- predict(model, test_data, n = 5)
# For simplicity, just count how many recommended items were actually in the test set
# This is a basic recall-like metric
hits <- 0
total <- 0
for (i in 1:length(test_indices)) {
user_id <- test_indices[i]
recommended_items <- recom@items[[i]]
actual_items <- which(test_data[i, ] > 0)
# Count hits
common_items <- intersect(recommended_items, actual_items)
hits <- hits + length(common_items)
total <- total + length(actual_items)
}
# Calculate recall
recall <- ifelse(total > 0, hits / total, 0)
fold_results[[fold]] <- recall
}
# Average recall across folds
avg_recall <- mean(unlist(fold_results))
# Store result
results_df <- rbind(results_df, data.frame(k = k_val, recall = avg_recall))
}
# Load packages
library(dplyr)
library(tidyr)
library(recommenderlab)
# Step 1: Create binary interaction dataset (purchases)
data_rcs <- data
interactions <- data_rcs %>%
dplyr::select(customer_id, product_title) %>%
distinct() %>%
mutate(purchased = 1)
# Step 2: Sample a subset of customers
set.seed(42)
sample_customers <- sample(unique(interactions$customer_id), 1000)
sample_data <- interactions %>%
filter(customer_id %in% sample_customers)
# Step 3: Filter to top 100 most purchased products
top_products <- sample_data %>%
dplyr::count(product_title, sort = TRUE) %>%
slice_head(n = 100) %>%
pull(product_title)
sample_data <- sample_data %>%
filter(product_title %in% top_products)
# Step 4: Create wide user-product matrix (1 = purchased)
interaction_matrix <- sample_data %>%
tidyr::pivot_wider(
names_from = product_title,
values_from = purchased,
values_fill = list(purchased = 0)
)
# Step 5: Convert to matrix format
customer_ids <- interaction_matrix$customer_id
interaction_matrix <- interaction_matrix %>% dplyr::select(-customer_id)
mat <- as.matrix(interaction_matrix)
rownames(mat) <- customer_ids
# Step 6: Convert to binaryRatingMatrix
binary_ratings <- as(mat, "binaryRatingMatrix")
# Remove sparse customers/products
filtered_ratings <- binary_ratings[rowCounts(binary_ratings) > 2, colCounts(binary_ratings) > 5]
# Define parameters to test
k_values <- c(10, 20, 30, 50, 100)
# Create a wrapper function to evaluate with specific parameters
evaluate_IBCF <- function(ratings_matrix, k) {
# Use a simple 80/20 split repeated 3 times (simpler than k-fold)
results <- replicate(3, {
# Create train/test split
set.seed(sample.int(1000, 1))  # Different seed each time for variety
which_train <- sample(c(TRUE, FALSE), nrow(ratings_matrix), replace = TRUE, prob = c(0.8, 0.2))
train_data <- ratings_matrix[which_train, ]
test_data <- ratings_matrix[!which_train, ]
# Build model with current k
model <- Recommender(train_data, method = "IBCF", parameter = list(k = k))
# Predict top 5 recommendations
preds <- predict(model, test_data, n = 5)
# Get performance metrics using recommenderlab
getList(preds)  # Return the list to make manual evaluation easier
})
return(results)
}
# Test each k value and store results
cat("Testing different k values for IBCF model\n")
performance_results <- list()
for (k in k_values) {
cat("Testing k =", k, "\n")
tryCatch({
results <- evaluate_IBCF(filtered_ratings, k)
performance_results[[as.character(k)]] <- results
cat("  Completed successfully\n")
}, error = function(e) {
cat("  Error:", e$message, "\n")
})
}
# Manual parameter tuning - avoid complex matrix operations
# Build final model with k=30 (middle value) if no results were successful
best_k <- 30
if (length(performance_results) > 0) {
# Use k with best performance if we have results
best_k_name <- names(performance_results)[1]  # Default to first one that worked
cat("Using k =", best_k_name, "for final model\n")
best_k <- as.numeric(best_k_name)
}
# Final train/test split
set.seed(42)
which_train <- sample(x = c(TRUE, FALSE),
size = nrow(filtered_ratings),
replace = TRUE,
prob = c(0.8, 0.2))
train_data <- filtered_ratings[which_train, ]
test_data <- filtered_ratings[!which_train, ]
# Build final model with best k parameter
final_model <- Recommender(train_data, method = "IBCF", parameter = list(k = best_k))
# Make predictions
n_recommended <- 5
predicted <- predict(final_model, newdata = test_data, n = n_recommended)
# Convert to list & assign correct names
recommendation_list <- as(predicted, "list")
names(recommendation_list) <- rownames(test_data)
# Show first 3 users' recommendations
recommendation_list[1:3]
# Simple evaluation - just see what % of recommendations are useful (precision-like metric)
cat("Final model using k =", best_k, "\n")
