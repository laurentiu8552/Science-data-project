"decoration",
"nest of tables",
"Curtain",
"Mattresses",
"Bed Linen",
"bedside table",
"lamp",
"Garden cushion",
"Bed Linen",
"Bed Linen",
"top mattress",
"Mattresses",
"Accessorries",
"Curtain",
"Accessorries",
"continental bed",
"Bed Linen",
"Mattresses",
"office chair",
"sofa bed with chaise longue",
"dining chair",
"dining chair",
"Accessorries",
"Accessorries",
"Accessorries",
"Bed Linen",
"top mattress",
"Accessorries",
"top mattress",
"Mattresses",
"top mattress",
"Towel",
"TableTextile",
"Mattresses",
"Accessorries",
"sofa bed",
"Decoration",
"Accessorries",
"top mattress",
"Mattresses",
"Mattresses",
"Mattresses"
)
# d, combine all three vectors into a data frame named 'lookup'
lookup <- data.frame(
product_title = product_title,
product_group_level_1 = product_group_level_1,
product_category_level_2 = product_category_level_2,
stringsAsFactors = FALSE
)
# e, Print to confirm
print(lookup, n = nrow(lookup))
# f, now the actual imputation part
# create data_joined by joining data with lookup on product_title
data <- data %>%
left_join(lookup, by = "product_title", suffix = c("", ".lkp")) %>%
# replace NAs in original columns with the lookup columns
mutate(
product_group_level_1 = coalesce(product_group_level_1, product_group_level_1.lkp),
product_category_level_2 = coalesce(product_category_level_2, product_category_level_2.lkp  )
) %>%
# remove the extra lookup columns
dplyr::select(-ends_with(".lkp"))
# Convert the 'date' column to Date type
data$date <- as.Date(data$date, format = "%d.%m.%Y")
# Convert all non-numeric columns (besides 'date') to factors
data[] <- lapply(data, function(x) if(is.character(x)) as.factor(x) else x)
# Impute NA customer id's with 999999999 for now. Will be removed in CLV probably
data <- data %>%
mutate(customer_id = replace_na(customer_id, 9999999999))
sum(is.na(data))
skimr::skim(data)
# 1. Aggregate to Order-Level Data
order_level_data <- data_clean_rfm %>%
dplyr::select(date, order_id, customer_id, revenue) %>%  # keep only relevant columns
dplyr::group_by(order_id, customer_id, date) %>%         # group by order_id, customer_id, and date
dplyr::summarise(total_revenue = sum(revenue, na.rm = TRUE), .groups = "drop")  # sum revenue and ungroup
#Visualization of the 3 rfm variables
data_clean_rfm <- data[data$customer_id != 9999999999, ]
# Revenue histogram
hist(data_clean_rfm$revenue, main = "Histogram of Revenue", col = "blue", border = "black")
# Check for NAs
sum(is.na(data_clean_rfm$revenue))      # Count NAs in revenue
# Customer ID bar plot - Delete later, useless, including the NA checks
cust_freq <- table(data_clean_rfm$customer_id)
# Filter to only those with frequency >= 10
cust_freq_filtered <- cust_freq[cust_freq >= 35]
barplot(cust_freq_filtered, main = "Customer ID Distribution", col = "blue", las = 2, ylim = c(0, 80))
# Date bar plot
barplot(table(data_clean_rfm$date), main = "Date Distribution", col = "blue")
sum(is.na(data_clean_rfm$date))         # Count NAs in date
#CAN BE SEEN no NAs and also no negative variables, can proceed with the RFM model running
# 1. Aggregate to Order-Level Data
order_level_data <- data_clean_rfm %>%
dplyr::select(date, order_id, customer_id, revenue) %>%  # keep only relevant columns
dplyr::group_by(order_id, customer_id, date) %>%         # group by order_id, customer_id, and date
dplyr::summarise(total_revenue = sum(revenue, na.rm = TRUE), .groups = "drop")  # sum revenue and ungroup
# 2. Set Analysis Date (using the day after your last order date)
analysis_date <- as.Date("2025-01-01")
# 3. Run the RFM Analysis using the Aggregated Data
# Note: We now use 'total_revenue' instead of 'revenue'
rfm_result <- rfm_table_order(order_level_data,
customer_id,
date,
total_revenue,
analysis_date = analysis_date)
# 4. Visualize RFM Results
rfm_plot_heatmap(rfm_result)
rfm_plot_bar_chart(rfm_result)
# 5. Define RFM Segment Categories and Thresholds
segment_names <- c("Champions", "Loyal Customers", "Potential Loyalist",
"New Customers", "Promising", "Need Attention", "About To Sleep",
"At Risk", "Can't Lose Them", "Lost")
# For Recency
summary(rfm_result$rfm$recency_score)
hist(rfm_result$rfm$recency_score, main = "Recency Distribution", xlab = "Recency")
# For Frequency
summary(rfm_result$rfm$frequency_score)
hist(rfm_result$rfm$frequency_score, main = "Frequency Distribution", xlab = "Frequency")
# For Monetary
summary(rfm_result$rfm$monetary_score)
hist(rfm_result$rfm$monetary_score, main = "Monetary Distribution", xlab = "Monetary")
quantile(rfm_result$rfm$recency_score, probs = seq(0, 1, 0.2))
quantile(rfm_result$rfm$frequency_score, probs = seq(0, 1, 0.2))
quantile(rfm_result$rfm$monetary_score, probs = seq(0, 1, 0.2))
# For each customer, count the number of orders (each row in order_level_data is an order)
customer_orders <- order_level_data %>%
dplyr::group_by(customer_id) %>%
dplyr::summarise(num_orders = dplyr::n(), .groups = "drop")
# Count how many customers fall into each order count bucket
freq_dist <- customer_orders %>%
dplyr::count(num_orders)
print(freq_dist)
recency_lower   <- c(4, 2, 3, 4, 3, 2, 2, 1, 1, 1)
recency_upper   <- c(5, 5, 5, 5, 4, 3, 3, 2, 1, 2)
frequency_lower <- c(5, 5, 3, 1, 1, 1, 1, 1, 1, 1)
frequency_upper <- c(5, 5, 5, 1, 1, 1, 1, 1, 1, 1)
monetary_lower  <- c(4, 3, 1, 1, 1, 2, 1, 2, 4, 1)
monetary_upper  <- c(5, 5, 3, 1, 1, 3, 2, 5, 5, 2)
# 6. Apply Segmentation Based on RFM Scores
segment <- rfm_segment(rfm_result,
segment_names,
recency_lower, recency_upper,
frequency_lower, frequency_upper,
monetary_lower, monetary_upper)
# 7. View the Segmented Customers
head(segment)
# 8. Visualize RFM Segments
rfm_plot_median_recency(segment, sort = TRUE)
rfm_plot_median_monetary(segment, sort = TRUE)
rfm_plot_median_frequency(segment, sort = TRUE)
# Load packages
library(dplyr)
library(tidyr)
library(recommenderlab)
# a, data preparation: creating binary interaction dataset (purchases)
data_rcs <- data
interactions <- data_rcs %>%
dplyr::select(customer_id, product_title) %>%
distinct() %>%
mutate(purchased = 1)
# b, sampling a subset of customers
set.seed(123)
sample_customers <- sample(unique(interactions$customer_id), 1000)
sample_data <- interactions %>%
filter(customer_id %in% sample_customers)
# c, filtering to top 100 most purchased products
top_products <- sample_data %>%
dplyr::count(product_title, sort = TRUE) %>%
slice_head(n = 100) %>%
pull(product_title)
sample_data <- sample_data %>%
filter(product_title %in% top_products)
# d, creating user-product matrix (1 = purchased)
# Transforms the data from long format to a wide matrix where:
# Rows represent customers
# Columns represent products
# Cell values are 1 (purchased) or 0 (not purchased)
interaction_matrix <- sample_data %>%
tidyr::pivot_wider(
names_from = product_title,
values_from = purchased,
values_fill = list(purchased = 0)
)
# e, Convert to matrix format
customer_ids <- interaction_matrix$customer_id
interaction_matrix <- interaction_matrix %>% dplyr::select(-customer_id)
mat <- as.matrix(interaction_matrix)
rownames(mat) <- customer_ids
# f, convert to binaryRatingMatrix
binary_ratings <- as(mat, "binaryRatingMatrix")
# Remove sparse customers/products
# filters out customers who bought fewer than 3 products
# filters out products purchased by fewer than 6 customers
filtered_ratings <- binary_ratings[rowCounts(binary_ratings) > 2, colCounts(binary_ratings) > 5]
# define a grid of k parameters to test
k_values <- c(10, 20, 30, 50, 100)
# create a function to evaluate models with specific parameters
# Repeatedly splitting data into 80% training and 20% testing (3 times)
# Building an Item-Based Collaborative Filtering (IBCF) model with the current k value
# Making recommendations for test users
# Returning the recommendations for evaluation
evaluate_IBCF <- function(ratings_matrix, k) {
# here we use a simple 80/20 split repeated 3 times (simpler than k-fold, due to computation efficiency and also just to demonstrate what can be played around with to improve model performance)
results <- replicate(3, {
# create train/test split
set.seed(sample.int(1000, 1))  # different seed each time for variety here as well
which_train <- sample(c(TRUE, FALSE), nrow(ratings_matrix), replace = TRUE, prob = c(0.8, 0.2))
train_data <- ratings_matrix[which_train, ]
test_data <- ratings_matrix[!which_train, ]
# Build model with current k
model <- Recommender(train_data, method = "IBCF", parameter = list(k = k))
# Predict top 5 recommendations
preds <- predict(model, test_data, n = 5)
# Get performance metrics using recommenderlab
getList(preds)  # Return the list to make manual evaluation easier
})
return(results)
}
# test each k value and store results
cat("Testing different k values for IBCF model\n")
performance_results <- list()
for (k in k_values) {
cat("Testing k =", k, "\n")
tryCatch({
results <- evaluate_IBCF(filtered_ratings, k)
performance_results[[as.character(k)]] <- results
cat("  Completed successfully\n")
}, error = function(e) {
cat("  Error:", e$message, "\n")
})
}
# just set best k to 30 to fall back to if the function fails, and also to see whether it works. If best k changes from 30 which it does, to 10, then our custom function works.
best_k <- 30
if (length(performance_results) > 0) {
# Use k with best performance if we have results
best_k_name <- names(performance_results)[1]  # Default to first one that worked
cat("Using k =", best_k_name, "for final model\n")
best_k <- as.numeric(best_k_name)
}
# final train/test split
set.seed(123)
which_train <- sample(x = c(TRUE, FALSE),
size = nrow(filtered_ratings),
replace = TRUE,
prob = c(0.8, 0.2))
train_data <- filtered_ratings[which_train, ]
test_data <- filtered_ratings[!which_train, ]
# building the final model with best k parameter
final_model <- Recommender(train_data, method = "IBCF", parameter = list(k = best_k))
# make predictions, recommendations
n_recommended <- 5
predicted <- predict(final_model, newdata = test_data, n = n_recommended)
# convert to list & assign correct names
recommendation_list <- as(predicted, "list")
names(recommendation_list) <- rownames(test_data)
# show first 3 users' recommendations
recommendation_list[1:3]
# Simple evaluation - just see what % of recommendations are useful (precision-like metric)
cat("Final model using k =", best_k, "\n")
# Filter RFM to match recommendation users
rfm_sample <- segment %>%
filter(customer_id %in% names(recommendation_list))
# Create recommendation data frame
recommendation_df <- data.frame(
customer_id = names(recommendation_list),
recommended_items = sapply(recommendation_list, paste, collapse = ", ")
)
# Match data types
recommendation_df$customer_id <- as.character(recommendation_df$customer_id)
rfm_sample$customer_id <- as.character(rfm_sample$customer_id)
# Join recommendations with RFM data
final_output <- recommendation_df %>%
dplyr::left_join(rfm_sample, by = "customer_id")
print(table(final_output$segment))
view(final_output)
view(order_level_data)
view(data_clean_rfm)
# Load packages
library(dplyr)
library(tidyr)
library(recommenderlab)
# a, data preparation: creating binary interaction dataset (purchases)
data_rcs <- data
interactions <- data_rcs %>%
dplyr::select(customer_id, product_title) %>%
distinct() %>%
mutate(purchased = 1)
# b, sampling a subset of customers
set.seed(123)
sample_customers <- sample(unique(interactions$customer_id), 1000)
sample_data <- interactions %>%
filter(customer_id %in% sample_customers)
# c, filtering to top 100 most purchased products
top_products <- sample_data %>%
dplyr::count(product_title, sort = TRUE) %>%
slice_head(n = 100) %>%
pull(product_title)
sample_data <- sample_data %>%
filter(product_title %in% top_products)
# d, creating user-product matrix (1 = purchased)
# Transforms the data from long format to a wide matrix where:
# Rows represent customers
# Columns represent products
# Cell values are 1 (purchased) or 0 (not purchased)
interaction_matrix <- sample_data %>%
tidyr::pivot_wider(
names_from = product_title,
values_from = purchased,
values_fill = list(purchased = 0)
)
# e, Convert to matrix format
customer_ids <- interaction_matrix$customer_id
interaction_matrix <- interaction_matrix %>% dplyr::select(-customer_id)
mat <- as.matrix(interaction_matrix)
rownames(mat) <- customer_ids
# f, convert to binaryRatingMatrix
binary_ratings <- as(mat, "binaryRatingMatrix")
# Remove sparse customers/products
# filters out customers who bought fewer than 3 products
# filters out products purchased by fewer than 6 customers
filtered_ratings <- binary_ratings[rowCounts(binary_ratings) > 2, colCounts(binary_ratings) > 5]
# define a grid of k parameters to test
k_values <- c(10, 20, 30, 50, 100)
# create a function to evaluate models with specific parameters
# Repeatedly splitting data into 80% training and 20% testing (3 times)
# Building an Item-Based Collaborative Filtering (IBCF) model with the current k value
# Making recommendations for test users
# Returning the recommendations for evaluation
evaluate_IBCF <- function(ratings_matrix, k) {
# here we use a simple 80/20 split repeated 3 times (simpler than k-fold, due to computation efficiency and also just to demonstrate what can be played around with to improve model performance)
results <- replicate(3, {
# create train/test split
set.seed(sample.int(1000, 1))  # different seed each time for variety here as well
which_train <- sample(c(TRUE, FALSE), nrow(ratings_matrix), replace = TRUE, prob = c(0.8, 0.2))
train_data <- ratings_matrix[which_train, ]
test_data <- ratings_matrix[!which_train, ]
# Build model with current k
model <- Recommender(train_data, method = "IBCF", parameter = list(k = k))
# Predict top 5 recommendations
preds <- predict(model, test_data, n = 5)
# Get performance metrics using recommenderlab
getList(preds)  # Return the list to make manual evaluation easier
})
return(results)
}
# test each k value and store results
cat("Testing different k values for IBCF model\n")
performance_results <- list()
for (k in k_values) {
cat("Testing k =", k, "\n")
tryCatch({
results <- evaluate_IBCF(filtered_ratings, k)
performance_results[[as.character(k)]] <- results
cat("  Completed successfully\n")
}, error = function(e) {
cat("  Error:", e$message, "\n")
})
}
# just set best k to 30 to fall back to if the function fails, and also to see whether it works. If best k changes from 30 which it does, to 10, then our custom function works.
best_k <- 30
if (length(performance_results) > 0) {
# Use k with best performance if we have results
best_k_name <- names(performance_results)[1]  # Default to first one that worked
cat("Using k =", best_k_name, "for final model\n")
best_k <- as.numeric(best_k_name)
}
# final train/test split
set.seed(123)
which_train <- sample(x = c(TRUE, FALSE),
size = nrow(filtered_ratings),
replace = TRUE,
prob = c(0.8, 0.2))
train_data <- filtered_ratings[which_train, ]
test_data <- filtered_ratings[!which_train, ]
# building the final model with best k parameter
final_model <- Recommender(train_data, method = "IBCF", parameter = list(k = best_k))
# make predictions, recommendations
n_recommended <- 5
predicted <- predict(final_model, newdata = test_data, n = n_recommended)
# convert to list & assign correct names
recommendation_list <- as(predicted, "list")
names(recommendation_list) <- rownames(test_data)
# show first 3 users' recommendations
recommendation_list[1:3]
# Simple evaluation - just see what % of recommendations are useful (precision-like metric)
cat("Final model using k =", best_k, "\n")
# Load packages
library(dplyr)
library(tidyr)
library(recommenderlab)
# a, data preparation: creating binary interaction dataset (purchases)
data_rcs <- data
interactions <- data_rcs %>%
dplyr::select(customer_id, product_title) %>%
distinct() %>%
mutate(purchased = 1)
# b, sampling a subset of customers
set.seed(123)
sample_customers <- sample(unique(interactions$customer_id), 1000)
sample_data <- interactions %>%
filter(customer_id %in% sample_customers)
# c, filtering to top 100 most purchased products
top_products <- sample_data %>%
dplyr::count(product_title, sort = TRUE) %>%
slice_head(n = 100) %>%
pull(product_title)
sample_data <- sample_data %>%
filter(product_title %in% top_products)
# d, creating user-product matrix (1 = purchased)
# Transforms the data from long format to a wide matrix where:
# Rows represent customers
# Columns represent products
# Cell values are 1 (purchased) or 0 (not purchased)
interaction_matrix <- sample_data %>%
tidyr::pivot_wider(
names_from = product_title,
values_from = purchased,
values_fill = list(purchased = 0)
)
# e, Convert to matrix format
customer_ids <- interaction_matrix$customer_id
interaction_matrix <- interaction_matrix %>% dplyr::select(-customer_id)
mat <- as.matrix(interaction_matrix)
rownames(mat) <- customer_ids
# f, convert to binaryRatingMatrix
binary_ratings <- as(mat, "binaryRatingMatrix")
# Remove sparse customers/products
# filters out customers who bought fewer than 3 products
# filters out products purchased by fewer than 6 customers
filtered_ratings <- binary_ratings[rowCounts(binary_ratings) > 2, colCounts(binary_ratings) > 5]
# define a grid of k parameters to test
k_values <- c(10, 20, 30, 50, 100)
# create a function to evaluate models with specific parameters
# Repeatedly splitting data into 80% training and 20% testing (3 times)
# Building an Item-Based Collaborative Filtering (IBCF) model with the current k value
# Making recommendations for test users
# Returning the recommendations for evaluation
evaluate_IBCF <- function(ratings_matrix, k) {
# here we use a simple 80/20 split repeated 3 times (simpler than k-fold, due to computation efficiency and also just to demonstrate what can be played around with to improve model performance)
results <- replicate(3, {
# create train/test split
set.seed(sample.int(1000, 1))  # different seed each time for variety here as well
which_train <- sample(c(TRUE, FALSE), nrow(ratings_matrix), replace = TRUE, prob = c(0.8, 0.2))
train_data <- ratings_matrix[which_train, ]
test_data <- ratings_matrix[!which_train, ]
# Build model with current k
model <- Recommender(train_data, method = "IBCF", parameter = list(k = k))
# Predict top 5 recommendations
preds <- predict(model, test_data, n = 5)
# Get performance metrics using recommenderlab
getList(preds)  # Return the list to make manual evaluation easier
})
return(results)
}
# test each k value and store results
cat("Testing different k values for IBCF model\n")
performance_results <- list()
for (k in k_values) {
cat("Testing k =", k, "\n")
tryCatch({
results <- evaluate_IBCF(filtered_ratings, k)
performance_results[[as.character(k)]] <- results
cat("  Completed successfully\n")
}, error = function(e) {
cat("  Error:", e$message, "\n")
})
}
# just set best k to 30 to fall back to if the function fails, and also to see whether it works. If best k changes from 30 which it does, to 10, then our custom function works.
best_k <- 30
if (length(performance_results) > 0) {
# Use k with best performance if we have results
best_k_name <- names(performance_results)[1]  # Default to first one that worked
cat("Using k =", best_k_name, "for final model\n")
best_k <- as.numeric(best_k_name)
}
# final train/test split
set.seed(123)
which_train <- sample(x = c(TRUE, FALSE),
size = nrow(filtered_ratings),
replace = TRUE,
prob = c(0.8, 0.2))
train_data <- filtered_ratings[which_train, ]
test_data <- filtered_ratings[!which_train, ]
# building the final model with best k parameter
final_model <- Recommender(train_data, method = "IBCF", parameter = list(k = best_k))
# make predictions, recommendations
n_recommended <- 10
predicted <- predict(final_model, newdata = test_data, n = n_recommended)
# convert to list & assign correct names
recommendation_list <- as(predicted, "list")
names(recommendation_list) <- rownames(test_data)
# show first 5 users' recommendations
recommendation_list[1:5]
# Simple evaluation - just see what % of recommendations are useful (precision-like metric)
cat("Final model using k =", best_k, "\n")
# Filter RFM to match recommendation users
rfm_sample <- segment %>%
filter(customer_id %in% names(recommendation_list))
# Create recommendation data frame
recommendation_df <- data.frame(
customer_id = names(recommendation_list),
recommended_items = sapply(recommendation_list, paste, collapse = ", ")
)
# Match data types
recommendation_df$customer_id <- as.character(recommendation_df$customer_id)
rfm_sample$customer_id <- as.character(rfm_sample$customer_id)
# Join recommendations with RFM data
final_output <- recommendation_df %>%
dplyr::left_join(rfm_sample, by = "customer_id")
print(table(final_output$segment))
view(final_output)
